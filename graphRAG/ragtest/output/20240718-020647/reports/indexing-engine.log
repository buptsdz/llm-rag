02:06:47,465 graphrag.config.read_dotenv INFO Loading pipeline .env file
02:06:47,474 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 51",
        "type": "openai_chat",
        "model": "deepseek-chat",
        "max_tokens": 4000,
        "request_timeout": 180.0,
        "api_base": "https://api.agicto.cn/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": false,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./ragtest",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://api.agicto.cn/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "deepseek-chat",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://api.agicto.cn/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": false,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "deepseek-chat",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://api.agicto.cn/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": false,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "deepseek-chat",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://api.agicto.cn/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": false,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": null,
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 51",
            "type": "openai_chat",
            "model": "deepseek-chat",
            "max_tokens": 4000,
            "request_timeout": 180.0,
            "api_base": "https://api.agicto.cn/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": false,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 0,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
02:06:47,476 graphrag.index.create_pipeline_config INFO skipping workflows 
02:06:47,479 graphrag.index.run INFO Running pipeline
02:06:47,479 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at ragtest\output\20240718-020647\artifacts
02:06:47,482 graphrag.index.input.load_input INFO loading input from root_dir=input
02:06:47,482 graphrag.index.input.load_input INFO using file storage for input
02:06:47,484 graphrag.index.storage.file_pipeline_storage INFO search ragtest\input for files matching .*\.txt$
02:06:47,485 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
02:06:47,491 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
02:06:47,491 graphrag.index.run INFO Final # of rows loaded: 1
02:06:47,672 graphrag.index.run INFO Running workflow: create_base_text_units...
02:06:47,672 graphrag.index.run INFO dependencies for create_base_text_units: []
02:06:47,677 datashaper.workflow.workflow INFO executing verb orderby
02:06:47,682 datashaper.workflow.workflow INFO executing verb zip
02:06:47,687 datashaper.workflow.workflow INFO executing verb aggregate_override
02:06:47,698 datashaper.workflow.workflow INFO executing verb chunk
02:06:47,938 datashaper.workflow.workflow INFO executing verb select
02:06:47,944 datashaper.workflow.workflow INFO executing verb unroll
02:06:47,953 datashaper.workflow.workflow INFO executing verb rename
02:06:47,962 datashaper.workflow.workflow INFO executing verb genid
02:06:47,976 datashaper.workflow.workflow INFO executing verb unzip
02:06:47,984 datashaper.workflow.workflow INFO executing verb copy
02:06:47,990 datashaper.workflow.workflow INFO executing verb filter
02:06:48,4 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
02:06:48,244 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
02:06:48,245 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
02:06:48,245 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
02:06:48,281 datashaper.workflow.workflow INFO executing verb entity_extract
02:06:48,304 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.agicto.cn/v1
02:06:48,940 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for deepseek-chat: TPM=0, RPM=0
02:06:48,941 graphrag.index.llm.load_llm INFO create concurrency limiter for deepseek-chat: 25
02:06:49,419 datashaper.workflow.workflow INFO executing verb merge_graphs
02:06:49,534 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
02:06:49,735 graphrag.index.run INFO Running workflow: create_summarized_entities...
02:06:49,736 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
02:06:49,736 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
02:06:49,754 datashaper.workflow.workflow INFO executing verb summarize_descriptions
02:06:50,529 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
02:06:50,732 graphrag.index.run INFO Running workflow: create_base_entity_graph...
02:06:50,732 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
02:06:50,734 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
02:06:50,752 datashaper.workflow.workflow INFO executing verb cluster_graph
02:06:51,49 datashaper.workflow.workflow INFO executing verb select
02:06:51,54 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
02:06:51,277 graphrag.index.run INFO Running workflow: create_final_entities...
02:06:51,278 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
02:06:51,278 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
02:06:51,301 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:51,394 datashaper.workflow.workflow INFO executing verb rename
02:06:51,402 datashaper.workflow.workflow INFO executing verb select
02:06:51,410 datashaper.workflow.workflow INFO executing verb dedupe
02:06:51,423 datashaper.workflow.workflow INFO executing verb rename
02:06:51,432 datashaper.workflow.workflow INFO executing verb filter
02:06:51,458 datashaper.workflow.workflow INFO executing verb text_split
02:06:51,479 datashaper.workflow.workflow INFO executing verb drop
02:06:51,489 datashaper.workflow.workflow INFO executing verb merge
02:06:51,583 datashaper.workflow.workflow INFO executing verb text_embed
02:06:51,587 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://api.agicto.cn/v1
02:06:52,245 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
02:06:52,245 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
02:06:52,282 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 430 inputs via 430 snippets using 27 batches. max_batch_size=16, max_tokens=8191
02:06:52,631 datashaper.workflow.workflow INFO executing verb drop
02:06:52,646 datashaper.workflow.workflow INFO executing verb filter
02:06:52,671 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
02:06:52,994 graphrag.index.run INFO Running workflow: create_final_nodes...
02:06:52,995 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
02:06:52,995 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
02:06:53,24 datashaper.workflow.workflow INFO executing verb layout_graph
02:06:53,671 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:53,805 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:53,928 datashaper.workflow.workflow INFO executing verb filter
02:06:53,977 datashaper.workflow.workflow INFO executing verb drop
02:06:53,992 datashaper.workflow.workflow INFO executing verb select
02:06:54,6 datashaper.workflow.workflow INFO executing verb rename
02:06:54,21 datashaper.workflow.workflow INFO executing verb join
02:06:54,46 datashaper.workflow.workflow INFO executing verb convert
02:06:54,95 datashaper.workflow.workflow INFO executing verb rename
02:06:54,98 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
02:06:54,331 graphrag.index.run INFO Running workflow: create_final_communities...
02:06:54,331 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
02:06:54,331 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
02:06:54,365 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:54,494 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:54,645 datashaper.workflow.workflow INFO executing verb aggregate_override
02:06:54,666 datashaper.workflow.workflow INFO executing verb join
02:06:54,695 datashaper.workflow.workflow INFO executing verb join
02:06:54,719 datashaper.workflow.workflow INFO executing verb concat
02:06:54,736 datashaper.workflow.workflow INFO executing verb filter
02:06:54,979 datashaper.workflow.workflow INFO executing verb aggregate_override
02:06:55,13 datashaper.workflow.workflow INFO executing verb join
02:06:55,36 datashaper.workflow.workflow INFO executing verb filter
02:06:55,78 datashaper.workflow.workflow INFO executing verb fill
02:06:55,96 datashaper.workflow.workflow INFO executing verb merge
02:06:55,133 datashaper.workflow.workflow INFO executing verb copy
02:06:55,150 datashaper.workflow.workflow INFO executing verb select
02:06:55,154 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
02:06:55,403 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
02:06:55,404 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
02:06:55,404 graphrag.index.run INFO read table from storage: create_final_entities.parquet
02:06:55,478 datashaper.workflow.workflow INFO executing verb select
02:06:55,501 datashaper.workflow.workflow INFO executing verb unroll
02:06:55,525 datashaper.workflow.workflow INFO executing verb aggregate_override
02:06:55,538 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
02:06:55,785 graphrag.index.run INFO Running workflow: create_final_relationships...
02:06:55,790 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
02:06:55,800 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
02:06:55,808 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
02:06:55,867 datashaper.workflow.workflow INFO executing verb unpack_graph
02:06:55,996 datashaper.workflow.workflow INFO executing verb filter
02:06:56,57 datashaper.workflow.workflow INFO executing verb rename
02:06:56,80 datashaper.workflow.workflow INFO executing verb filter
02:06:56,143 datashaper.workflow.workflow INFO executing verb drop
02:06:56,168 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
02:06:56,194 datashaper.workflow.workflow INFO executing verb convert
02:06:56,244 datashaper.workflow.workflow INFO executing verb convert
02:06:56,246 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
02:06:56,504 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
02:06:56,504 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
02:06:56,506 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
02:06:56,556 datashaper.workflow.workflow INFO executing verb select
02:06:56,580 datashaper.workflow.workflow INFO executing verb unroll
02:06:56,605 datashaper.workflow.workflow INFO executing verb aggregate_override
02:06:56,638 datashaper.workflow.workflow INFO executing verb select
02:06:56,642 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
02:06:56,919 graphrag.index.run INFO Running workflow: create_final_community_reports...
02:06:56,925 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
02:06:56,944 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
02:06:56,952 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
02:06:57,18 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
02:06:57,68 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
02:06:57,102 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
02:06:57,138 datashaper.workflow.workflow INFO executing verb prepare_community_reports
02:06:57,139 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 430
02:06:57,279 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 430
02:06:57,495 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 430
02:06:57,670 datashaper.workflow.workflow INFO executing verb create_community_reports
02:07:23,606 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:23,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.79699999996228. input_tokens=2140, output_tokens=394
02:07:26,437 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:26,439 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 28.625. input_tokens=2174, output_tokens=443
02:07:30,472 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:30,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 32.68699999997625. input_tokens=2185, output_tokens=520
02:07:31,891 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:31,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.125. input_tokens=2529, output_tokens=535
02:07:32,97 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:32,99 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.28099999995902. input_tokens=2357, output_tokens=548
02:07:32,918 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:32,919 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 35.07900000002701. input_tokens=2581, output_tokens=539
02:07:34,877 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:34,879 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.10899999999674. input_tokens=2702, output_tokens=601
02:07:35,691 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:35,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.875. input_tokens=2630, output_tokens=588
02:07:38,811 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:38,813 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.03100000001723. input_tokens=2290, output_tokens=660
02:07:39,508 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:39,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.75. input_tokens=4446, output_tokens=662
02:07:39,602 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:39,604 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.79699999996228. input_tokens=3113, output_tokens=647
02:07:41,968 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:41,971 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 44.23399999999674. input_tokens=2832, output_tokens=705
02:07:42,153 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:42,166 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 44.42200000002049. input_tokens=3031, output_tokens=694
02:07:43,830 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:43,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 46.0. input_tokens=2476, output_tokens=728
02:07:44,260 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:44,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 46.5. input_tokens=3097, output_tokens=725
02:07:44,384 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:44,386 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 46.56199999997625. input_tokens=3735, output_tokens=728
02:07:45,902 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:45,905 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 48.17200000002049. input_tokens=2820, output_tokens=779
02:07:47,516 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:47,518 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 49.79700000002049. input_tokens=3198, output_tokens=758
02:07:48,562 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:48,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 50.84400000004098. input_tokens=16732, output_tokens=775
02:07:55,102 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:55,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 57.31199999997625. input_tokens=4745, output_tokens=885
02:07:55,463 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:07:55,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 57.70299999997951. input_tokens=3998, output_tokens=903
02:08:19,570 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:19,572 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 81.78100000001723. input_tokens=5337, output_tokens=1308
02:08:24,927 graphrag.index.reporting.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\nYou are an AI assistant that helps a human analyst to perform general information discovery. Information discovery is the process of identifying and assessing relevant information associated with certain entities (e.g., organizations and individuals) within a network.\n\n# Goal\nWrite a comprehensive report of a community, given a list of entities that belong to the community as well as their relationships and optional associated claims. The report will be used to inform decision-makers about information associated with the community and their potential impact. The content of this report includes an overview of the community\'s key entities, their legal compliance, technical capabilities, reputation, and noteworthy claims.\n\n# Report Structure\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\n\n# Example Input\n-----------\nText:\n\nEntities\n\nid,entity,description\n5,VERDANT OASIS PLAZA,Verdant Oasis Plaza is the location of the Unity March\n6,HARMONY ASSEMBLY,Harmony Assembly is an organization that is holding a march at Verdant Oasis Plaza\n\nRelationships\n\nid,source,target,description\n37,VERDANT OASIS PLAZA,UNITY MARCH,Verdant Oasis Plaza is the location of the Unity March\n38,VERDANT OASIS PLAZA,HARMONY ASSEMBLY,Harmony Assembly is holding a march at Verdant Oasis Plaza\n39,VERDANT OASIS PLAZA,UNITY MARCH,The Unity March is taking place at Verdant Oasis Plaza\n40,VERDANT OASIS PLAZA,TRIBUNE SPOTLIGHT,Tribune Spotlight is reporting on the Unity march taking place at Verdant Oasis Plaza\n41,VERDANT OASIS PLAZA,BAILEY ASADI,Bailey Asadi is speaking at Verdant Oasis Plaza about the march\n43,HARMONY ASSEMBLY,UNITY MARCH,Harmony Assembly is organizing the Unity March\n\nOutput:\n{{\n    "title": "Verdant Oasis Plaza and Unity March",\n    "summary": "The community revolves around the Verdant Oasis Plaza, which is the location of the Unity March. The plaza has relationships with the Harmony Assembly, Unity March, and Tribune Spotlight, all of which are associated with the march event.",\n    "rating": 5.0,\n    "rating_explanation": "The impact severity rating is moderate due to the potential for unrest or conflict during the Unity March.",\n    "findings": [\n        {{\n            "summary": "Verdant Oasis Plaza as the central location",\n            "explanation": "Verdant Oasis Plaza is the central entity in this community, serving as the location for the Unity March. This plaza is the common link between all other entities, suggesting its significance in the community. The plaza\'s association with the march could potentially lead to issues such as public disorder or conflict, depending on the nature of the march and the reactions it provokes. [Data: Entities (5), Relationships (37, 38, 39, 40, 41,+more)]"\n        }},\n        {{\n            "summary": "Harmony Assembly\'s role in the community",\n            "explanation": "Harmony Assembly is another key entity in this community, being the organizer of the march at Verdant Oasis Plaza. The nature of Harmony Assembly and its march could be a potential source of threat, depending on their objectives and the reactions they provoke. The relationship between Harmony Assembly and the plaza is crucial in understanding the dynamics of this community. [Data: Entities(6), Relationships (38, 43)]"\n        }},\n        {{\n            "summary": "Unity March as a significant event",\n            "explanation": "The Unity March is a significant event taking place at Verdant Oasis Plaza. This event is a key factor in the community\'s dynamics and could be a potential source of threat, depending on the nature of the march and the reactions it provokes. The relationship between the march and the plaza is crucial in understanding the dynamics of this community. [Data: Relationships (39)]"\n        }},\n        {{\n            "summary": "Role of Tribune Spotlight",\n            "explanation": "Tribune Spotlight is reporting on the Unity March taking place in Verdant Oasis Plaza. This suggests that the event has attracted media attention, which could amplify its impact on the community. The role of Tribune Spotlight could be significant in shaping public perception of the event and the entities involved. [Data: Relationships (40)]"\n        }}\n    ]\n}}\n\n\n# Real Data\n\nUse the following text for your answer. Do not make anything up in your answer.\n\nText:\n-----Entities-----\nhuman_readable_id,title,description,degree\r\n401,"""PROJECT GUTENBERG\u2122""","Project Gutenberg\u2122 is a renowned organization dedicated to the free distribution of electronic works, primarily focusing on those not protected by U.S. copyright law. Operated by the Project Gutenberg Literary Archive Foundation, it is supported by a network of volunteers and relies on donations. The initiative aims to make public domain and licensed works freely available in machine-readable form, emphasizing compliance with specific terms and conditions for use and distribution. Project Gutenberg\u2122 is a trademark owned by the Foundation and is associated with electronic works, which are created, transcribed, and proofread by volunteers and employees. The organization produces and distributes eBooks in various formats, requiring a royalty fee for their use and specific guidelines for distribution and fees. It also owns a compilation copyright in the collection of its electronic works, often providing works with permission of the copyright holder and emphasizing the importance of adhering to the stipulated terms and conditions for redistribution. Overall, Project Gutenberg\u2122 is synonymous with the mission of promoting free access to electronic works, highlighting its commitment to intellectual property agreements and the free distribution of literature.",18\r\n403,"""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","The Project Gutenberg Literary Archive Foundation (PGLAF) is a multifaceted non-profit organization that plays a crucial role in the preservation and distribution of Project Gutenberg\u2122 electronic works. As the owner of the compilation copyright in the Project Gutenberg\u2122 collection, PGLAF ensures the secure and permanent future of these works. The foundation is responsible for managing donations, ensuring compliance with U.S. laws regulating charities and charitable donations, and is the direct recipient of funds intended to support the production of new eBooks and other activities related to Project Gutenberg\u2122. Additionally, PGLAF manages the Project Gutenberg\u2122 trademark, oversees permissions and operations related to the distribution of these electronic works, and is involved in distributing works under various agreements. Furthermore, the foundation receives royalty donations from the use of Project Gutenberg\u2122 works, reinforcing its commitment to maintaining and expanding the collection.",5\r\n422,"""DONATIONS""","Donations refer to the financial contributions made by people to support the efforts of volunteers in Project Gutenberg\u2122 and its mission. These contributions are essential for sustaining the operations of Project Gutenberg, which aims to provide free access to a vast collection of eBooks and other digital texts.",3\r\n406,"""COPYRIGHT HOLDER""","""The Copyright Holder is an individual or entity that holds the rights to a work and can grant permission for its use and distribution.""",2\r\n407,"""REDISTRIBUTION""","""Redistribution refers to the act of copying and distributing a Project Gutenberg\u2122 electronic work, which must comply with certain legal requirements.""",2\r\n405,"""COPYRIGHT LAWS""","""Copyright Laws are described as governing the use of Project Gutenberg\u2122 works, with specific mention of their variability across different countries.""",1\r\n414,"""DEFECTS""","""Defects refer to issues such as incomplete, inaccurate, or corrupt data, transcription errors, copyright infringements, and technical problems with the storage medium or computer codes in the Project Gutenberg\u2122 collection.""",1\r\n402,"""GENERAL TERMS OF USE AND REDISTRIBUTING PROJECT GUTENBERG\u2122 ELECTRONIC WORKS""","""This event refers to the process of reading, understanding, and agreeing to the terms of use and redistribution of Project Gutenberg\u2122 electronic works.""",1\r\n408,"""PLAIN VANILLA ASCII""","""Plain Vanilla ASCII is a specified format for the distribution of Project Gutenberg\u2122 works, which must be adhered to unless additional provisions are made for other formats or upon request for alternate formats.""",1\r\n410,"""PROJECT GUTENBERG\u2122 WEBSITE""","""The official website of Project Gutenberg\u2122, located at www.gutenberg.org, where the official versions of works are posted.""",1\r\n404,"""THE FOUNDATION""","""The Foundation is mentioned as an entity that makes no representations concerning the copyright status of any work in countries other than the United States.""",1\r\n409,"""WWW.GUTENBERG.ORG""","""www.gutenberg.org is the official website for Project Gutenberg\u2122, serving as the primary platform for information about the organization, its activities, and opportunities for donations and volunteering. Additionally, it is the designated site where the official versions of works are posted.""",1\r\n411,"""ROYALTY FEE""","""A 20% royalty fee on gross profits derived from the use of Project Gutenberg\u2122 works, calculated using existing tax methods, and donated to the Project Gutenberg Literary Organization.""",1\r\n413,"""U.S. COPYRIGHT LAW""","""U.S. Copyright Law refers to the legal framework governing copyright in the United States, which influences the activities of Project Gutenberg\u2122 in terms of what works they can include in their collection.""",1\r\n421,"""VOLUNTEERS""","""Volunteers are individuals who contribute efforts to support Project Gutenberg\u2122, playing a critical role in its mission.""",1\r\n429,"""THE PERSON""","""The Person refers to the individual who has been producing and distributing Project Gutenberg\u2122 eBooks for forty years, likely the founder or a key figure in the organization.""",1\r\n412,"""THE TRADEMARK OWNER""","""The Trademark Owner is the individual who owns the Project Gutenberg\u2122 trademark and agrees to donate royalties to the Project Gutenberg Literary Archive Foundation.""",1\r\n\n\n-----Relationships-----\nhuman_readable_id,source,target,description,rank\r\n560,"""PROJECT GUTENBERG\u2122""","""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","""Project Gutenberg\u2122 is a renowned initiative associated with the Project Gutenberg Literary Archive Foundation, which plays a pivotal role in managing and overseeing the creation and distribution of the Project Gutenberg\u2122 collection. The Foundation not only owns the Project Gutenberg\u2122 trademark but also ensures its secure and permanent future. It handles all legal aspects, including permissions, and is responsible for the distribution of Project Gutenberg\u2122 works. Additionally, the Foundation receives support and donations through the Project Gutenberg\u2122 organization, and the royalties generated from Project Gutenberg\u2122 works are donated back to the Foundation, reinforcing its mission to provide free access to literary works.""",23\r\n574,"""PROJECT GUTENBERG\u2122""","""GUTENBERG LITERARY ARCHIVE FOUNDATION""","""The Gutenberg Literary Archive Foundation provides support and ensures the future of Project Gutenberg\u2122.""",22\r\n388,"""UNITED STATES""","""PROJECT GUTENBERG\u2122""","Project Gutenberg\u2122 operates within the legal framework of the United States, particularly regarding copyright laws and the distribution of electronic works. It primarily considers the United States for understanding the copyright status of its works.",22\r\n573,"""PROJECT GUTENBERG\u2122""","""DONATIONS""","""Donations help provide the necessary assistance to volunteers, ensuring the continued availability of Project Gutenberg\u2122¡¯s works.""",21\r\n563,"""PROJECT GUTENBERG\u2122""","""COPYRIGHT HOLDER""","""Project Gutenberg\u2122 requires permission from the Copyright Holder for certain uses and distributions of electronic works.""",20\r\n564,"""PROJECT GUTENBERG\u2122""","""REDISTRIBUTION""","""Redistribution of a Project Gutenberg\u2122 electronic work must comply with the organization\'s specific terms and conditions.""",20\r\n571,"""PROJECT GUTENBERG\u2122""","""FOUNDATION""","""The Foundation is involved in the production, promotion, and distribution of Project Gutenberg\u2122 electronic works, indicating a direct organizational relationship.""",20\r\n562,"""PROJECT GUTENBERG\u2122""","""COPYRIGHT LAWS""","""Project Gutenberg\u2122 operates within the framework of Copyright Laws, which vary by country and affect the distribution and use of its works.""",19\r\n570,"""PROJECT GUTENBERG\u2122""","""DEFECTS""","""The Project Gutenberg\u2122 collection may contain Defects, which are issues identified during the creation and distribution process.""",19\r\n559,"""PROJECT GUTENBERG\u2122""","""GENERAL TERMS OF USE AND REDISTRIBUTING PROJECT GUTENBERG\u2122 ELECTRONIC WORKS""","""Project Gutenberg\u2122 is the organization that sets and enforces the terms of use and redistribution for its electronic works.""",19\r\n565,"""PROJECT GUTENBERG\u2122""","""PLAIN VANILLA ASCII""","""Project Gutenberg\u2122, an entity known for its digital library of free eBooks, mandates that all works included in its collection must be provided in the original Plain Vanilla ASCII format. This requirement is stringent, ensuring that the official works adhere to this specific format unless alternative provisions are explicitly made. The use of Plain Vanilla ASCII format is a key specification for the distribution of works within Project Gutenberg\u2122, maintaining a standard for accessibility and uniformity across its vast library.""",19\r\n567,"""PROJECT GUTENBERG\u2122""","""PROJECT GUTENBERG\u2122 WEBSITE""","""The official versions of Project Gutenberg\u2122 works are posted on the Project Gutenberg\u2122 website.""",19\r\n561,"""PROJECT GUTENBERG\u2122""","""THE FOUNDATION""","""Project Gutenberg\u2122 is associated with The Foundation, which oversees the copyright status of its works in various countries.""",19\r\n566,"""PROJECT GUTENBERG\u2122""","""WWW.GUTENBERG.ORG""","Project Gutenberg\u2122, operating its main website at www.gutenberg.org, serves as a central hub for information and activities related to the organization. This online platform not only facilitates the dissemination of the organization\'s official works but also solidifies its online presence by providing a direct link to its extensive collection of digital books and resources.",19\r\n568,"""PROJECT GUTENBERG\u2122""","""ROYALTY FEE""","""Project Gutenberg\u2122 collects a 20% royalty fee on gross profits from the use of its works, which is donated to the Project Gutenberg Literary Organization.""",19\r\n569,"""PROJECT GUTENBERG\u2122""","""U.S. COPYRIGHT LAW""","""Project Gutenberg\u2122 operates within the constraints and guidelines set by U.S. Copyright Law, focusing on works that are not protected by this law.""",19\r\n572,"""PROJECT GUTENBERG\u2122""","""VOLUNTEERS""","""Volunteers are essential to reaching Project Gutenberg\u2122¡¯s goals and maintaining its collection.""",19\r\n575,"""PROJECT GUTENBERG\u2122""","""THE PERSON""","""The Person has been instrumental in the production and distribution of Project Gutenberg\u2122 eBooks for four decades.""",19\r\n6,"""PROJECT GUTENBERG""","""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","""The Project Gutenberg Literary Archive Foundation manages donations and compliance for Project Gutenberg.""",15\r\n7,"""PROJECT GUTENBERG""","""DONATIONS""","""Project Gutenberg depends on donations to carry out its mission.""",13\r\n389,"""UNITED STATES""","""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","""The Foundation complies with charity laws in all 50 states of the United States.""",9\r\n577,"""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","""DONATIONS""","""The Foundation manages and ensures the proper handling of donations.""",8\r\n576,"""PROJECT GUTENBERG LITERARY ARCHIVE FOUNDATION""","""THE TRADEMARK OWNER""","""The Trademark Owner agrees to donate royalties from Project Gutenberg\u2122 works to the Project Gutenberg Literary Archive Foundation.""",6\r\n578,"""COPYRIGHT HOLDER""","""REDISTRIBUTION""","""Redistribution of a work with the permission of the Copyright Holder must adhere to both Project Gutenberg\u2122 terms and any additional terms imposed by the holder.""",4\r\n\n\nThe report should include the following sections:\n\n- TITLE: community\'s name that represents its key entities - title should be short but specific. When possible, include representative named entities in the title.\n- SUMMARY: An executive summary of the community\'s overall structure, how its entities are related to each other, and significant information associated with its entities.\n- IMPACT SEVERITY RATING: a float score between 0-10 that represents the severity of IMPACT posed by entities within the community.  IMPACT is the scored importance of a community.\n- RATING EXPLANATION: Give a single sentence explanation of the IMPACT severity rating.\n- DETAILED FINDINGS: A list of 5-10 key insights about the community. Each insight should have a short summary followed by multiple paragraphs of explanatory text grounded according to the grounding rules below. Be comprehensive.\n\nReturn output as a well-formed JSON-formatted string with the following format:\n    {{\n        "title": <report_title>,\n        "summary": <executive_summary>,\n        "rating": <impact_severity_rating>,\n        "rating_explanation": <rating_explanation>,\n        "findings": [\n            {{\n                "summary":<insight_1_summary>,\n                "explanation": <insight_1_explanation>\n            }},\n            {{\n                "summary":<insight_2_summary>,\n                "explanation": <insight_2_explanation>\n            }}\n        ]\n    }}\n\n# Grounding Rules\n\nPoints supported by data should list their data references as follows:\n\n"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)]."\n\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add "+more" to indicate that there are more.\n\nFor example:\n"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Reports (1), Entities (5, 7); Relationships (23); Claims (7, 2, 34, 64, 46, +more)]."\n\nwhere 1, 5, 7, 23, 2, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n\nDo not include information where the supporting evidence for it is not provided.\n\nOutput:'}
02:08:45,97 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:45,99 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.31199999997625. input_tokens=2102, output_tokens=373
02:08:45,245 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:45,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.40700000000652. input_tokens=2099, output_tokens=381
02:08:52,575 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:52,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 32.84400000004098. input_tokens=2263, output_tokens=491
02:08:54,368 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:54,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.625. input_tokens=2144, output_tokens=534
02:08:54,974 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:54,975 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 35.14100000000326. input_tokens=2269, output_tokens=544
02:08:58,800 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:58,803 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 39.01500000001397. input_tokens=2365, output_tokens=618
02:08:59,540 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:08:59,542 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 39.78200000000652. input_tokens=2414, output_tokens=618
02:09:00,4 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:00,5 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 40.28100000001723. input_tokens=2163, output_tokens=641
02:09:00,86 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:00,87 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 40.31199999997625. input_tokens=2754, output_tokens=645
02:09:01,50 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:01,52 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.23399999999674. input_tokens=2755, output_tokens=656
02:09:01,392 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:01,393 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.60899999999674. input_tokens=3173, output_tokens=651
02:09:02,847 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:02,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 43.14100000000326. input_tokens=3323, output_tokens=708
02:09:03,644 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:03,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 43.82799999997951. input_tokens=3025, output_tokens=679
02:09:04,13 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:04,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 44.23399999999674. input_tokens=2795, output_tokens=691
02:09:05,81 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:05,83 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 45.375. input_tokens=6344, output_tokens=706
02:09:05,604 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:05,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 45.84399999998277. input_tokens=3490, output_tokens=728
02:09:07,372 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:07,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 47.54699999996228. input_tokens=4037, output_tokens=709
02:09:09,433 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:09,435 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 49.65600000001723. input_tokens=3560, output_tokens=821
02:09:11,912 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:11,914 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 1 retries took 45.34399999998277. input_tokens=4356, output_tokens=706
02:09:13,94 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:13,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 53.375. input_tokens=2695, output_tokens=859
02:09:13,229 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:13,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 53.46899999998277. input_tokens=3435, output_tokens=865
02:09:13,609 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:13,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 53.79699999996228. input_tokens=5771, output_tokens=847
02:09:15,364 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:15,367 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 55.56299999996554. input_tokens=5484, output_tokens=872
02:09:17,736 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:17,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 23.375. input_tokens=2086, output_tokens=379
02:09:21,62 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:21,66 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 61.36000000004424. input_tokens=2825, output_tokens=1000
02:09:21,633 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:21,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 61.89000000001397. input_tokens=4317, output_tokens=994
02:09:22,818 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:22,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.73399999999674. input_tokens=2591, output_tokens=624
02:09:27,521 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:27,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 23.51600000000326. input_tokens=2101, output_tokens=390
02:09:29,812 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:29,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.84400000004098. input_tokens=2301, output_tokens=576
02:09:30,362 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:30,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 31.56299999996554. input_tokens=2230, output_tokens=534
02:09:31,912 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:31,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 39.34399999998277. input_tokens=3348, output_tokens=633
02:09:32,259 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:32,260 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 32.25. input_tokens=2295, output_tokens=537
02:09:32,572 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:32,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 29.719000000040978. input_tokens=2316, output_tokens=484
02:09:32,736 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:32,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 31.68799999996554. input_tokens=2340, output_tokens=518
02:09:33,613 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:33,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 48.375. input_tokens=3301, output_tokens=798
02:09:34,847 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:34,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.76600000000326. input_tokens=2381, output_tokens=579
02:09:35,962 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:35,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 36.42099999997299. input_tokens=2324, output_tokens=608
02:09:37,713 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:37,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 36.31199999997625. input_tokens=2605, output_tokens=597
02:09:41,476 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:41,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.82799999997951. input_tokens=2919, output_tokens=618
02:09:52,503 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:09:52,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 47.42200000002049. input_tokens=5551, output_tokens=767
02:10:18,944 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:18,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.28100000001723. input_tokens=2081, output_tokens=399
02:10:20,27 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:20,28 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 27.25. input_tokens=2117, output_tokens=441
02:10:20,802 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:20,804 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 28.094000000040978. input_tokens=2130, output_tokens=425
02:10:23,238 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:23,240 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 30.51600000000326. input_tokens=2233, output_tokens=485
02:10:24,476 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:24,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 31.70299999997951. input_tokens=2199, output_tokens=491
02:10:27,174 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:27,176 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 34.48399999999674. input_tokens=2126, output_tokens=558
02:10:28,565 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:28,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 35.86000000004424. input_tokens=2204, output_tokens=573
02:10:29,503 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:29,505 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 36.78100000001723. input_tokens=2247, output_tokens=582
02:10:29,920 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:29,922 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.21899999998277. input_tokens=4326, output_tokens=570
02:10:30,547 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:30,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.84399999998277. input_tokens=2443, output_tokens=606
02:10:30,719 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:30,721 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 38.04699999996228. input_tokens=2413, output_tokens=591
02:10:30,986 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:30,988 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 38.25. input_tokens=2297, output_tokens=622
02:10:31,833 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:31,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 39.15599999995902. input_tokens=2523, output_tokens=626
02:10:33,657 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:33,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.0. input_tokens=2705, output_tokens=678
02:10:33,774 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:33,776 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.01600000000326. input_tokens=2533, output_tokens=650
02:10:36,358 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:36,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 43.70299999997951. input_tokens=3245, output_tokens=703
02:10:37,985 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:37,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 45.20299999997951. input_tokens=5601, output_tokens=714
02:10:38,929 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:38,930 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 46.20300000003772. input_tokens=6072, output_tokens=734
02:10:42,289 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:42,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 49.48499999998603. input_tokens=9333, output_tokens=771
02:10:43,772 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:43,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 51.01600000000326. input_tokens=10605, output_tokens=840
02:10:46,102 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:46,103 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 53.35899999999674. input_tokens=5489, output_tokens=842
02:10:53,434 httpx INFO HTTP Request: POST https://api.agicto.cn/v1/chat/completions "HTTP/1.1 200 OK"
02:10:53,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 60.65600000001723. input_tokens=6400, output_tokens=922
02:10:53,501 datashaper.workflow.workflow INFO executing verb window
02:10:53,505 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
02:10:53,801 graphrag.index.run INFO Running workflow: create_final_text_units...
02:10:53,801 graphrag.index.run INFO dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids']
02:10:53,802 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
02:10:53,807 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
02:10:53,813 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
02:10:53,868 datashaper.workflow.workflow INFO executing verb select
02:10:53,903 datashaper.workflow.workflow INFO executing verb rename
02:10:53,932 datashaper.workflow.workflow INFO executing verb join
02:10:53,968 datashaper.workflow.workflow INFO executing verb join
02:10:54,0 datashaper.workflow.workflow INFO executing verb aggregate_override
02:10:54,51 datashaper.workflow.workflow INFO executing verb select
02:10:54,57 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
02:10:54,333 graphrag.index.run INFO Running workflow: create_base_documents...
02:10:54,339 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
02:10:54,356 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
02:10:54,419 datashaper.workflow.workflow INFO executing verb unroll
02:10:54,452 datashaper.workflow.workflow INFO executing verb select
02:10:54,481 datashaper.workflow.workflow INFO executing verb rename
02:10:54,511 datashaper.workflow.workflow INFO executing verb join
02:10:54,547 datashaper.workflow.workflow INFO executing verb aggregate_override
02:10:54,578 datashaper.workflow.workflow INFO executing verb join
02:10:54,612 datashaper.workflow.workflow INFO executing verb rename
02:10:54,646 datashaper.workflow.workflow INFO executing verb convert
02:10:54,682 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
02:10:54,954 graphrag.index.run INFO Running workflow: create_final_documents...
02:10:54,954 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
02:10:54,955 graphrag.index.run INFO read table from storage: create_base_documents.parquet
02:10:55,23 datashaper.workflow.workflow INFO executing verb rename
02:10:55,27 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
